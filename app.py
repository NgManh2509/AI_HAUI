import os
import cv2
import numpy as np
import streamlit as st

from PIL import ImageFont, ImageDraw, Image
from knn_func import load_knn_from_npz
from deepface import DeepFace

# =========================
# C·∫§U H√åNH ƒê∆Ø·ªúNG D·∫™N
# =========================
try:
    PROJECT_ROOT = os.path.dirname(os.path.abspath(__file__))
except NameError:
    PROJECT_ROOT = os.getcwd()

DATASET_PATH = os.path.join(PROJECT_ROOT, "dataset")
OUTPUT_DIR = os.path.join(PROJECT_ROOT, "output")
MODEL_PATH = os.path.join(OUTPUT_DIR, "model_knn.npz")

# DeepFace config
MODEL_NAME = "ArcFace"  # Ch√≠nh x√°c h∆°n Facenet
DETECTOR_BACKEND = "retinaface"
TARGET_IMAGES_PER_PERSON = 10      

# =========================
# C·∫§U H√åNH GIAO DI·ªÜN
# =========================
st.set_page_config(
    page_title="AI HAUI - Face Recognition with DeepFace",
    layout="wide",
    page_icon="üì∑",
)

st.markdown(
    """
    <style>
        .main-title {
            font-size: 30px;
            font-weight: 800;
            text-align: center;
            margin-bottom: 0.25rem;
        }
        .sub-title {
            text-align: center;
            font-size: 14px;
            color: #666666;
            margin-bottom: 1.5rem;
        }
        .step-box {
            padding: 1rem 1.2rem;
            border-radius: 0.6rem;
            border: 1px solid #e0e0e0;
            margin-bottom: 1rem;
            background-color: #fafafa;
        }
    </style>
    """,
    unsafe_allow_html=True,
)

# =========================
# LOAD MODEL KNN
# =========================
knn_model = load_knn_from_npz(MODEL_PATH)

# =========================
# H√ÄM TI·ªÜN √çCH
# =========================
def _save_image(frame, person_folder_path: str):
    """L∆∞u ·∫£nh BGR v√†o dataset (h·ªó tr·ª£ Unicode path)"""
    if not os.path.exists(person_folder_path):
        os.makedirs(person_folder_path, exist_ok=True)

    try:
        is_success, img_encoded = cv2.imencode(".jpg", frame, [cv2.IMWRITE_JPEG_QUALITY, 95])
        if not is_success:
            return False, "L·ªói m√£ h√≥a ·∫£nh"

        count = len([f for f in os.listdir(person_folder_path) 
                    if os.path.isfile(os.path.join(person_folder_path, f))]) + 1

        file_path = os.path.join(person_folder_path, f"{count}.jpg")

        with open(file_path, "wb") as f:
            f.write(img_encoded.tobytes())

        return True, file_path
    except Exception as e:
        return False, str(e)


def detect_and_extract_faces(bgr_image):
    try:
        rgb_image = cv2.cvtColor(bgr_image, cv2.COLOR_BGR2RGB)
        #Nh·∫≠n di·ªán khu√¥n m·∫∑t
        face_objs = DeepFace.extract_faces(
            img_path=rgb_image,
            detector_backend=DETECTOR_BACKEND,
            enforce_detection=False,
            align=True
        )
        
        if not face_objs:
            return []
        
        results = []
        # Tr·∫£ v·ªÅ danh s√°ch (face_bgr, facial_area)
        for face_obj in face_objs:
            facial_area = face_obj['facial_area']
            x, y, w, h = facial_area['x'], facial_area['y'], facial_area['w'], facial_area['h']
            
            face_bgr = bgr_image[y:y+h, x:x+w]
            results.append((face_bgr, facial_area))
        
        return results
    except Exception as e:
        print(f"L·ªói detect face: {e}")
        return []


def draw_rounded_rectangle(img, top_left, bottom_right, color, thickness=2, radius=15):
    """
    V·∫Ω khung bo g√≥c b·∫±ng line + ellipse.
    """
    x1, y1 = top_left
    x2, y2 = bottom_right

    radius = int(min(radius, (x2 - x1) / 2, (y2 - y1) / 2))

    cv2.line(img, (x1 + radius, y1), (x2 - radius, y1), color, thickness)
    cv2.line(img, (x1 + radius, y2), (x2 - radius, y2), color, thickness)
    cv2.line(img, (x1, y1 + radius), (x1, y2 - radius), color, thickness)
    cv2.line(img, (x2, y1 + radius), (x2, y2 - radius), color, thickness)

    cv2.ellipse(img, (x1 + radius, y1 + radius), (radius, radius), 180, 0, 90, color, thickness)
    cv2.ellipse(img, (x2 - radius, y1 + radius), (radius, radius), 270, 0, 90, color, thickness)
    cv2.ellipse(img, (x1 + radius, y2 - radius), (radius, radius), 90, 0, 90, color, thickness)
    cv2.ellipse(img, (x2 - radius, y2 - radius), (radius, radius), 0, 0, 90, color, thickness)


def predict_name_from_face(face_bgr, confidence_threshold=3.7):
    if knn_model is None:
        return "Unknown", None

    try:
        face_rgb = cv2.cvtColor(face_bgr, cv2.COLOR_BGR2RGB)
        
        result = DeepFace.represent(
            img_path=face_rgb,
            model_name=MODEL_NAME,
            detector_backend=DETECTOR_BACKEND,
            enforce_detection=False
        )
        
        embedding = result[0]["embedding"]
        pred = knn_model.predict(embedding)[0]
        
        # T√≠nh distance ƒë·ªÉ ƒë√°nh gi√° confidence
        X_train = knn_model.X_train
        distances = np.linalg.norm(X_train - np.array(embedding), axis=1)
        min_distance = np.min(distances)
        
        # N·∫øu distance qu√° l·ªõn th√¨ coi l√† Unknown
        # V·ªõi Facenet: distance < 10 th∆∞·ªùng l√† same person
        if min_distance > confidence_threshold:
            return "Unknown", min_distance
        
        return str(pred), min_distance
        
    except Exception as e:
        print(f"Error predicting: {e}")
        return "Unknown", None

def draw_vietnamese_text(img_bgr, text, pos, font_size=24, color=(0, 255, 0)):
    img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)
    img_pil = Image.fromarray(img_rgb)
    draw = ImageDraw.Draw(img_pil)

    font = ImageFont.truetype("arial.ttf", font_size)

    draw.text(pos, text, font=font, fill=color)

    return cv2.cvtColor(np.array(img_pil), cv2.COLOR_RGB2BGR)


# =========================
# PAGE 1: CH·ª§P ·∫¢NH
# =========================
def page_chup_anh():
    st.markdown('<div class="main-title">H·ªÜ TH·ªêNG NH·∫¨N DI·ªÜN KHU√îN M·∫∂T</div>', unsafe_allow_html=True)
    st.markdown(
        '<div class="sub-title">Thu th·∫≠p d·ªØ li·ªáu v·ªõi DeepFace RetinaFace Detection</div>',
        unsafe_allow_html=True,
    )

    st.markdown('<div class="step-box">', unsafe_allow_html=True)
    st.subheader("üì∏ Ch·ª•p ·∫£nh thu th·∫≠p d·ªØ li·ªáu")

    person_name = st.text_input(
        "Nh·∫≠p t√™n (c√≥ th·ªÉ c√≥ d·∫•u, v√≠ d·ª•: M·∫°nh, Khang, Nguy·ªÖn VƒÉn A):",
        "",
    )

    if person_name.strip():
        person_folder_path = os.path.join(DATASET_PATH, person_name.strip())
        current_count = 0
        if os.path.exists(person_folder_path):
            current_count = len(
                [
                    f
                    for f in os.listdir(person_folder_path)
                    if os.path.isfile(os.path.join(person_folder_path, f))
                ]
            )
        st.info(f"Hi·ªán c√≥ {current_count} ·∫£nh c·ªßa `{person_name}` trong dataset.")
        st.progress(min(current_count / TARGET_IMAGES_PER_PERSON, 1.0))
    else:
        st.warning("H√£y nh·∫≠p t√™n tr∆∞·ªõc khi ch·ª•p ·∫£nh.")

    picture = st.camera_input("Ch·ª•p ·∫£nh khu√¥n m·∫∑t", key="camera_capture")

    if picture is not None:
        if not person_name.strip():
            st.error("B·∫°n ch∆∞a nh·∫≠p t√™n/m√£ ƒë·ªãnh danh.")
            return

        bytes_data = picture.getvalue()
        cv2_img = cv2.imdecode(np.frombuffer(bytes_data, np.uint8), cv2.IMREAD_COLOR)

        if cv2_img is None or cv2_img.size == 0:
            st.error("Kh√¥ng ƒë·ªçc ƒë∆∞·ª£c ·∫£nh t·ª´ camera.")
            return

        with st.spinner("ƒêang detect khu√¥n m·∫∑t..."):
            faces = detect_and_extract_faces(cv2_img)
        
        if not faces:
            st.error("Kh√¥ng t√¨m th·∫•y khu√¥n m·∫∑t. H√£y ch·ª•p l·∫°i g·∫ßn h∆°n / s√°ng h∆°n.")
            return
        
        # L·∫•y face l·ªõn nh·∫•t
        face_bgr, facial_area = max(faces, key=lambda f: f[1]['w'] * f[1]['h'])

        person_folder_path = os.path.join(DATASET_PATH, person_name.strip())
        success, path = _save_image(face_bgr, person_folder_path)

        if success:
            new_count = len([f for f in os.listdir(person_folder_path) 
                           if os.path.isfile(os.path.join(person_folder_path, f))])
            st.success(f"‚úÖ ƒê√£ l∆∞u ·∫£nh: {os.path.basename(path)}")
            st.info(f"üìä T·ªïng s·ªë ·∫£nh hi·ªán c√≥: {new_count}/{TARGET_IMAGES_PER_PERSON}")

            st.image(
                cv2.cvtColor(face_bgr, cv2.COLOR_BGR2RGB),
                caption=f"Khu√¥n m·∫∑t ƒë√£ l∆∞u ({facial_area['w']}x{facial_area['h']}px)",
                use_container_width=True,
            )
        else:
            st.error(f"L·ªói khi l∆∞u ·∫£nh: {path}")

    st.markdown("</div>", unsafe_allow_html=True)
    st.caption("‚ö° Sau khi ch·ª•p ƒë·ªß ·∫£nh, ch·∫°y `python train_model.py` ƒë·ªÉ train model.")


# =========================
# PAGE 2: NH·∫¨N DI·ªÜN ·∫¢NH UPLOAD
# =========================
def page_nhan_dien():
    st.markdown('<div class="main-title">NH·∫¨N DI·ªÜN KHU√îN M·∫∂T</div>', unsafe_allow_html=True)
    st.markdown(
        '<div class="sub-title">DeepFace RetinaFace + Facenet Embedding + KNN</div>',
        unsafe_allow_html=True,
    )

    if knn_model is None:
        st.error("‚ö†Ô∏è Ch∆∞a load ƒë∆∞·ª£c model KNN.\n\nH√£y ch·∫°y `python train_model.py` tr∆∞·ªõc.")
        return

    uploaded_img = st.file_uploader("Ch·ªçn ·∫£nh ƒë·ªÉ nh·∫≠n di·ªán", type=["jpg", "jpeg", "png"])

    if uploaded_img is None:
        return

    bytes_data = uploaded_img.read()
    cv2_img = cv2.imdecode(np.frombuffer(bytes_data, np.uint8), cv2.IMREAD_COLOR)

    if cv2_img is None or cv2_img.size == 0:
        st.error("Kh√¥ng ƒë·ªçc ƒë∆∞·ª£c ·∫£nh.")
        return

    # Detect faces
    with st.spinner("ƒêang ph√°t hi·ªán khu√¥n m·∫∑t..."):
        faces = detect_and_extract_faces(cv2_img)

    if not faces:
        st.warning("Kh√¥ng ph√°t hi·ªán khu√¥n m·∫∑t n√†o trong ·∫£nh.")
        st.image(cv2.cvtColor(cv2_img, cv2.COLOR_BGR2RGB), use_container_width=True)
        return

    # Predict cho t·ª´ng face
    recognized_count = 0
    unknown_count = 0
    
    with st.spinner(f"ƒêang nh·∫≠n di·ªán {len(faces)} khu√¥n m·∫∑t..."):
        for face_bgr, facial_area in faces:
            x, y, w, h = facial_area['x'], facial_area['y'], facial_area['w'], facial_area['h']
            
            name, distance = predict_name_from_face(face_bgr)
            
            # Ch·ªçn m√†u
            if name == "Unknown":
                box_color = (0, 0, 255)  # ƒê·ªè
                text_color = (0, 0, 255)
                unknown_count += 1
            else:
                box_color = (0, 255, 0)  # Xanh l√°
                text_color = (0, 255, 0)
                recognized_count += 1

            draw_rounded_rectangle(
                cv2_img,
                (x, y),
                (x + w, y + h),
                color=box_color,
                thickness=3,
                radius=20,
            )
            
            cv2_img = draw_vietnamese_text(
                cv2_img,
                name,
                (x, y - 35),      
                font_size=28,
                color=text_color
            )

    # Hi·ªÉn th·ªã k·∫øt qu·∫£
    if unknown_count == 0:
        st.success(f"‚úÖ Nh·∫≠n di·ªán th√†nh c√¥ng {recognized_count} khu√¥n m·∫∑t!")
    else:
        st.info(f"üìä K·∫øt qu·∫£: {recognized_count} nh·∫≠n di·ªán ƒë∆∞·ª£c, {unknown_count} kh√¥ng x√°c ƒë·ªãnh")
    
    st.image(
        cv2.cvtColor(cv2_img, cv2.COLOR_BGR2RGB),
        caption="K·∫øt qu·∫£ nh·∫≠n di·ªán",
        use_container_width=True,
    )


# =========================
# MAIN
# =========================
def main():
    st.sidebar.title("üéØ Menu")
    st.sidebar.info(f"**Model:** {MODEL_NAME}\n**Detector:** {DETECTOR_BACKEND}")
    
    choice = st.sidebar.radio("Ch·ªçn ch·ª©c nƒÉng", ["üì∏ Ch·ª•p ·∫£nh", "üîç Nh·∫≠n di·ªán"])

    if choice == "üì∏ Ch·ª•p ·∫£nh":
        page_chup_anh()
    else:
        page_nhan_dien()


if __name__ == "__main__":
    main()
