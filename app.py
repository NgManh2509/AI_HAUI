import streamlit as st
import cv2
import os
import numpy as np

# =========================
# C·∫§U H√åNH ƒê∆Ø·ªúNG D·∫™N
# =========================
try:
    PROJECT_ROOT = os.path.dirname(os.path.abspath(__file__))
except NameError:
    PROJECT_ROOT = os.getcwd()

DATASET_PATH = os.path.join(PROJECT_ROOT, "dataset")
HAAR_DIR = os.path.join(PROJECT_ROOT, "haar")
CASCADE_PATH = os.path.join(HAAR_DIR, "haarcascade_frontalface_default.xml")

if not os.path.exists(DATASET_PATH):
    os.makedirs(DATASET_PATH, exist_ok=True)

TARGET_IMAGES_PER_PERSON = 20  # s·ªë ·∫£nh g·ª£i √Ω n√™n ch·ª•p / ng∆∞·ªùi

# =========================
# C·∫§U H√åNH GIAO DI·ªÜN CHUNG
# =========================
st.set_page_config(
    page_title="AI HAUI - H·ªá th·ªëng Nh·∫≠n di·ªán khu√¥n m·∫∑t",
    layout="wide",
    page_icon="üì∑",
)

# CSS nh·∫π cho ƒë·∫πp
st.markdown(
    """
    <style>
        .main-title {
            font-size: 32px;
            font-weight: 800;
            text-align: center;
            margin-bottom: 0.25rem;
        }
        .sub-title {
            text-align: center;
            font-size: 14px;
            color: #666666;
            margin-bottom: 1.5rem;
        }
        .step-box, .dataset-box {
            padding: 1rem 1.2rem;
            border-radius: 0.6rem;
            border: 1px solid #e0e0e0;
            margin-bottom: 1rem;
        }
        .step-box {
            background-color: #fafafa;
        }
        .dataset-box {
            background-color: #ffffff;
        }
    </style>
    """,
    unsafe_allow_html=True,
)

# =========================
# KI·ªÇM TRA & LOAD HAAR CASCADE
# =========================
if not os.path.exists(CASCADE_PATH):
    st.error(
        f"Kh√¥ng t√¨m th·∫•y file cascade: `{CASCADE_PATH}`.\n\n"
        "H√£y t·∫£i file **haarcascade_frontalface_default.xml** t·ª´ OpenCV v√† ƒë·∫∑t v√†o th∆∞ m·ª•c `haar/`."
    )
    st.stop()

face_cascade = cv2.CascadeClassifier(CASCADE_PATH)
if face_cascade.empty():
    st.error("Kh√¥ng load ƒë∆∞·ª£c Haar Cascade. Ki·ªÉm tra l·∫°i file `haarcascade_frontalface_default.xml`.")
    st.stop()


# =========================
# H√ÄM L∆ØU ·∫¢NH
# =========================
def _save_image(frame, person_folder_path: str):
    """
    L∆∞u ·∫£nh (grayscale ho·∫∑c m√†u) v√†o th∆∞ m·ª•c dataset/<person>/.
    frame: numpy array (2D grayscale ho·∫∑c 3D BGR)
    """
    if not os.path.exists(person_folder_path):
        os.makedirs(person_folder_path, exist_ok=True)

    try:
        is_success, img_encoded = cv2.imencode(".jpg", frame)
        if is_success:
            count = len(
                [
                    f
                    for f in os.listdir(person_folder_path)
                    if os.path.isfile(os.path.join(person_folder_path, f))
                ]
            ) + 1
            file_path = os.path.join(person_folder_path, f"{count}.jpg")

            with open(file_path, "wb") as f:
                f.write(img_encoded.tobytes())

            print(f"ƒê√£ l∆∞u ·∫£nh: {file_path}")
            return True, file_path
        else:
            print("L·ªói: cv2.imencode() th·∫•t b·∫°i.")
            return False, "L·ªói m√£ h√≥a ·∫£nh"
    except Exception as e:
        print(f"L·ªói h·ªá th·ªëng khi l∆∞u file: {e}")
        return False, str(e)


# =========================
# H√ÄM PH√ÅT HI·ªÜN & CROP KHU√îN M·∫∂T
# =========================
def detect_and_crop_face_gray(bgr_image, expand_ratio=0.15):
    """
    - Chuy·ªÉn ·∫£nh sang grayscale
    - D√≤ m·∫∑t b·∫±ng Haar tr√™n ·∫£nh grayscale
    - Crop v√πng m·∫∑t (grayscale) + tr·∫£ th√™m b·∫£n m√†u ƒë·ªÉ preview
    """
    gray_frame = cv2.cvtColor(bgr_image, cv2.COLOR_BGR2GRAY)

    faces = face_cascade.detectMultiScale(
        gray_frame,
        scaleFactor=1.1,
        minNeighbors=5,
        minSize=(80, 80),
    )

    if len(faces) == 0:
        return None, None, None

    # L·∫•y khu√¥n m·∫∑t l·ªõn nh·∫•t (tr√°nh tr∆∞·ªùng h·ª£p c√≥ nhi·ªÅu ng∆∞·ªùi trong ·∫£nh)
    x, y, w, h = max(faces, key=lambda f: f[2] * f[3])

    # M·ªü r·ªông box m·ªôt ch√∫t cho ƒë·ª° c·∫Øt s√°t m·∫∑t
    h_expand = int(h * expand_ratio)
    w_expand = int(w * expand_ratio)

    y1 = max(0, y - h_expand)
    y2 = min(gray_frame.shape[0], y + h + h_expand)
    x1 = max(0, x - w_expand)
    x2 = min(gray_frame.shape[1], x + w + w_expand)

    face_gray = gray_frame[y1:y2, x1:x2].copy()
    face_color = bgr_image[y1:y2, x1:x2].copy()

    return face_gray, face_color, (x1, y1, x2, y2)


# =========================
# PAGE 1: CH·ª§P ·∫¢NH (THU TH·∫¨P D·ªÆ LI·ªÜU)
# =========================
def page_chup_anh():
    st.markdown('<div class="main-title">H·ªÜ TH·ªêNG NH·∫¨N DI·ªÜN KHU√îN M·∫∂T</div>', unsafe_allow_html=True)
    st.markdown(
        '<div class="sub-title">B∆∞·ªõc 1: Thu th·∫≠p d·ªØ li·ªáu khu√¥n m·∫∑t (crop & grayscale, l∆∞u v√†o dataset)</div>',
        unsafe_allow_html=True,
    )

    st.markdown('<div class="step-box">', unsafe_allow_html=True)
    st.subheader("üì∏ B∆∞·ªõc 1: Thu th·∫≠p d·ªØ li·ªáu khu√¥n m·∫∑t")

    st.write(
        "- Nh·∫≠p **t√™n ng∆∞·ªùi** (ho·∫∑c m√£ SV, m√£ nh√¢n vi√™n, ‚Ä¶)\n"
        "- Ch·ª•p nhi·ªÅu ·∫£nh v·ªõi c√°c g√≥c: **th·∫≥ng**, **nghi√™ng tr√°i**, **nghi√™ng ph·∫£i**, **bi·ªÉu c·∫£m kh√°c nhau**.\n"
        f"- Khuy·∫øn ngh·ªã: kho·∫£ng **10‚Äì{TARGET_IMAGES_PER_PERSON} ·∫£nh/ng∆∞·ªùi** ƒë·ªÉ train model t·ªët h∆°n."
    )

    person_name = st.text_input("Nh·∫≠p t√™n / m√£ ƒë·ªãnh danh c·ªßa b·∫°n:", "TenNguoiMau")

    # Th√¥ng tin s·ªë ·∫£nh hi·ªán c√≥ c·ªßa ng∆∞·ªùi n√†y
    person_folder_path = (
        os.path.join(DATASET_PATH, person_name.strip())
        if person_name.strip()
        else None
    )
    current_count = 0
    if person_folder_path and os.path.exists(person_folder_path):
        current_count = len(
            [
                f
                for f in os.listdir(person_folder_path)
                if os.path.isfile(os.path.join(person_folder_path, f))
            ]
        )

    if person_name and person_name.strip() and person_name != "TenNguoiMau":
        st.info(f"Hi·ªán t·∫°i ƒë√£ c√≥ **{current_count} ·∫£nh** c·ªßa `{person_name}` trong dataset.")
        progress = min(current_count / TARGET_IMAGES_PER_PERSON, 1.0)
        st.progress(progress)
        st.caption(f"M·ª•c ti√™u ƒë·ªÅ xu·∫•t: {TARGET_IMAGES_PER_PERSON} ·∫£nh / ng∆∞·ªùi")
    else:
        st.warning("Vui l√≤ng nh·∫≠p t√™n/m√£ ƒë·ªãnh danh th·ª±c t·∫ø tr∆∞·ªõc khi ch·ª•p ·∫£nh.")

    picture = st.camera_input(
        "Ch·ª•p ·∫£nh (Th·∫≥ng, Nghi√™ng tr√°i, Nghi√™ng ph·∫£i)",
        key="camera_capture",
    )

    if picture is not None:
        if not person_name or person_name == "TenNguoiMau" or person_name.strip() == "":
            st.error("‚ùå B·∫°n ch∆∞a nh·∫≠p t√™n/m√£ ƒë·ªãnh danh. Vui l√≤ng nh·∫≠p tr∆∞·ªõc khi ch·ª•p!")
        else:
            # Decode ·∫£nh t·ª´ camera
            bytes_data = picture.getvalue()
            cv2_img = cv2.imdecode(np.frombuffer(bytes_data, np.uint8), cv2.IMREAD_COLOR)

            if cv2_img is not None and cv2_img.size > 0:
                # Ph√°t hi·ªán & crop khu√¥n m·∫∑t (grayscale + preview m√†u)
                face_gray, face_color, box = detect_and_crop_face_gray(cv2_img)

                if face_gray is None:
                    st.error("Kh√¥ng t√¨m th·∫•y khu√¥n m·∫∑t trong ·∫£nh. H√£y ch·ª•p l·∫°i, cƒÉn m·∫∑t r√µ h∆°n.")
                else:
                    # L∆∞u ·∫£nh grayscale
                    person_folder_path = os.path.join(DATASET_PATH, person_name.strip())
                    success, path = _save_image(face_gray, person_folder_path)

                    if success:
                        new_count = len(
                            [
                                f
                                for f in os.listdir(person_folder_path)
                                if os.path.isfile(os.path.join(person_folder_path, f))
                            ]
                        )

                        st.success(f"‚úÖ ƒê√£ l∆∞u ·∫£nh khu√¥n m·∫∑t (grayscale): **{os.path.basename(path)}**")
                        st.info(f"T·ªïng s·ªë ·∫£nh hi·ªán c√≥ c·ªßa **{person_name}**: **{new_count}**")

                        # Hi·ªÉn th·ªã preview
                        st.write("üì∑ Khu√¥n m·∫∑t (m√†u) ƒë·ªÉ xem r√µ:")
                        st.image(cv2.cvtColor(face_color, cv2.COLOR_BGR2RGB), use_container_width=True)

                        st.write("üñ§ Khu√¥n m·∫∑t (grayscale) ƒë√£ l∆∞u:")
                        st.image(face_gray, use_container_width=True)

                        st.caption("üëâ Ti·∫øp t·ª•c ch·ª•p th√™m ·∫£nh v·ªõi nhi·ªÅu g√≥c kh√°c nhau ƒë·ªÉ dataset ƒëa d·∫°ng h∆°n.")
                    else:
                        st.error(f"‚ùå L·ªói khi l∆∞u ·∫£nh: {path}")
            else:
                st.error("Kh√¥ng th·ªÉ ƒë·ªçc d·ªØ li·ªáu ·∫£nh t·ª´ camera.")
    st.markdown("</div>", unsafe_allow_html=True)

    st.markdown("---")
    st.caption(
        "AI HAUI ‚Äì Giai ƒëo·∫°n 1: Thu th·∫≠p dataset khu√¥n m·∫∑t (crop + grayscale) ƒë·ªÉ train model KNN / face_recognition."
    )


# =========================
# PAGE 2: NH·∫¨N DI·ªÜN
# =========================
def page_nhan_dien():
    st.markdown('<div class="main-title">H·ªÜ TH·ªêNG NH·∫¨N DI·ªÜN KHU√îN M·∫∂T</div>', unsafe_allow_html=True)
    st.markdown(
        '<div class="sub-title">B∆∞·ªõc 2: Nh·∫≠n di·ªán khu√¥n m·∫∑t t·ª´ camera / ·∫£nh upload</div>',
        unsafe_allow_html=True,
    )

    st.subheader("üëÄ Nh·∫≠n di·ªán (demo)")
    st.info(
        "Ph·∫ßn n√†y b·∫°n c√≥ th·ªÉ:\n"
        "- Load model ƒë√£ train (KNN, LBPH, ho·∫∑c face_recognition)\n"
        "- M·ªü camera ho·∫∑c upload ·∫£nh, d√≤ m·∫∑t v√† g√°n t√™n theo dataset.\n\n"
        "Hi·ªán t·∫°i m√¨nh ch·ªâ t·∫°o s·∫µn khung giao di·ªán, b·∫°n nh√©t code nh·∫≠n di·ªán c·ªßa b·∫°n v√†o ƒë√¢y."
    )

    # V√≠ d·ª• khung upload ·∫£nh ƒë·ªÉ nh·∫≠n di·ªán
    uploaded_img = st.file_uploader("Upload ·∫£nh ƒë·ªÉ nh·∫≠n di·ªán khu√¥n m·∫∑t", type=["jpg", "jpeg", "png"])

    if uploaded_img is not None:
        bytes_data = uploaded_img.read()
        cv2_img = cv2.imdecode(np.frombuffer(bytes_data, np.uint8), cv2.IMREAD_COLOR)

        if cv2_img is None or cv2_img.size == 0:
            st.error("Kh√¥ng ƒë·ªçc ƒë∆∞·ª£c ·∫£nh. Th·ª≠ l·∫°i ·∫£nh kh√°c.")
            return

        gray = cv2.cvtColor(cv2_img, cv2.COLOR_BGR2GRAY)
        faces = face_cascade.detectMultiScale(gray, 1.1, 5, minSize=(80, 80))

        if len(faces) == 0:
            st.warning("Kh√¥ng ph√°t hi·ªán khu√¥n m·∫∑t n√†o trong ·∫£nh.")
        else:
            # V·∫Ω bounding box demo (ch∆∞a g·∫Øn t√™n)
            for (x, y, w, h) in faces:
                cv2.rectangle(cv2_img, (x, y), (x + w, y + h), (0, 255, 0), 2)

            st.image(cv2.cvtColor(cv2_img, cv2.COLOR_BGR2RGB), caption="·∫¢nh v·ªõi bounding box khu√¥n m·∫∑t", use_container_width=True)
            st.caption("üëâ Sau n√†y b·∫°n d√πng model nh·∫≠n di·ªán ƒë·ªÉ g√°n t√™n v√†o t·ª´ng khu√¥n m·∫∑t.")


# =========================
# MAIN: MENU BAR
# =========================
def main():
    # Sidebar menu
    st.sidebar.title("Menu")
    choice = st.sidebar.radio(
        "Ch·ªçn ch·ª©c nƒÉng",
        ["Ch·ª•p ·∫£nh", "Nh·∫≠n di·ªán"]
    )

    if choice == "Ch·ª•p ·∫£nh":
        page_chup_anh()
    else:
        page_nhan_dien()


if __name__ == "__main__":
    main()
