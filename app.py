import os
import cv2
import numpy as np
import streamlit as st

from knn_func import load_knn_from_npz

# =========================
# C·∫§U H√åNH ƒê∆Ø·ªúNG D·∫™N
# =========================
try:
    PROJECT_ROOT = os.path.dirname(os.path.abspath(__file__))
except NameError:
    PROJECT_ROOT = os.getcwd()

DATASET_PATH = os.path.join(PROJECT_ROOT, "dataset")
HAAR_DIR = os.path.join(PROJECT_ROOT, "haar")
CASCADE_PATH = os.path.join(HAAR_DIR, "haarcascade_frontalface_default.xml")

OUTPUT_DIR = os.path.join(PROJECT_ROOT, "output")
MODEL_PATH = os.path.join(OUTPUT_DIR, "model_knn.npz")

IMG_SIZE = (100, 100)               # k√≠ch th∆∞·ªõc ·∫£nh m·∫∑t ƒë·ªÉ train/predict
TARGET_IMAGES_PER_PERSON = 20       # g·ª£i √Ω s·ªë ·∫£nh n√™n ch·ª•p / ng∆∞·ªùi

# =========================
# C·∫§U H√åNH GIAO DI·ªÜN
# =========================
st.set_page_config(
    page_title="AI HAUI - H·ªá th·ªëng nh·∫≠n di·ªán khu√¥n m·∫∑t",
    layout="wide",
    page_icon="üì∑",
)

st.markdown(
    """
    <style>
        .main-title {
            font-size: 30px;
            font-weight: 800;
            text-align: center;
            margin-bottom: 0.25rem;
        }
        .sub-title {
            text-align: center;
            font-size: 14px;
            color: #666666;
            margin-bottom: 1.5rem;
        }
        .step-box {
            padding: 1rem 1.2rem;
            border-radius: 0.6rem;
            border: 1px solid #e0e0e0;
            margin-bottom: 1rem;
            background-color: #fafafa;
        }
    </style>
    """,
    unsafe_allow_html=True,
)

# =========================
# LOAD HAAR CASCADE
# =========================
if not os.path.exists(CASCADE_PATH):
    st.error(
        f"Kh√¥ng t√¨m th·∫•y file Haar Cascade: `{CASCADE_PATH}`.\n"
        "H√£y ƒë·∫∑t file `haarcascade_frontalface_default.xml` v√†o th∆∞ m·ª•c `haar/`."
    )
    st.stop()

face_cascade = cv2.CascadeClassifier(CASCADE_PATH)
if face_cascade.empty():
    st.error("Kh√¥ng load ƒë∆∞·ª£c Haar Cascade.")
    st.stop()

# =========================
# LOAD MODEL KNN T·ª™ NPZ
# =========================
knn_model = load_knn_from_npz(MODEL_PATH)

# =========================
# H√ÄM TI·ªÜN √çCH
# =========================
def _save_image(frame, person_folder_path: str):
    """
    L∆∞u 1 ·∫£nh (grayscale ho·∫∑c BGR) v√†o dataset/<person>/
    D√πng imencode + write ƒë·ªÉ tr√°nh l·ªói Unicode path.
    """
    if not os.path.exists(person_folder_path):
        os.makedirs(person_folder_path, exist_ok=True)

    try:
        is_success, img_encoded = cv2.imencode(".jpg", frame)
        if not is_success:
            return False, "L·ªói m√£ h√≥a ·∫£nh (cv2.imencode)"

        # ƒê·∫øm s·ªë file hi·ªán c√≥ ƒë·ªÉ ƒë·∫∑t t√™n ti·∫øp theo
        count = len(
            [
                f
                for f in os.listdir(person_folder_path)
                if os.path.isfile(os.path.join(person_folder_path, f))
            ]
        ) + 1

        file_path = os.path.join(person_folder_path, f"{count}.jpg")

        # Ghi file d·∫°ng nh·ªã ph√¢n
        with open(file_path, "wb") as f:
            f.write(img_encoded.tobytes())

        return True, file_path
    except Exception as e:
        return False, str(e)


def detect_and_crop_face_gray(bgr_image, expand_ratio=0.15):
    """
    - Chuy·ªÉn sang grayscale
    - D√≤ m·∫∑t b·∫±ng Haar
    - L·∫•y khu√¥n m·∫∑t l·ªõn nh·∫•t
    - M·ªü r·ªông box m·ªôt ch√∫t cho ƒë·ª° s√°t m·∫∑t
    Tr·∫£ v·ªÅ: face_gray, face_color, (x1, y1, x2, y2)
    """
    gray_frame = cv2.cvtColor(bgr_image, cv2.COLOR_BGR2GRAY)

    faces = face_cascade.detectMultiScale(
        gray_frame,
        scaleFactor=1.1,
        minNeighbors=5,
        minSize=(80, 80),
    )

    if len(faces) == 0:
        return None, None, None

    # l·∫•y khu√¥n m·∫∑t c√≥ di·ªán t√≠ch l·ªõn nh·∫•t
    x, y, w, h = max(faces, key=lambda f: f[2] * f[3])

    h_expand = int(h * expand_ratio)
    w_expand = int(w * expand_ratio)

    y1 = max(0, y - h_expand)
    y2 = min(gray_frame.shape[0], y + h + h_expand)
    x1 = max(0, x - w_expand)
    x2 = min(gray_frame.shape[1], x + w + w_expand)

    face_gray = gray_frame[y1:y2, x1:x2].copy()
    face_color = bgr_image[y1:y2, x1:x2].copy()

    return face_gray, face_color, (x1, y1, x2, y2)


def draw_rounded_rectangle(img, top_left, bottom_right, color, thickness=2, radius=15):
    """
    V·∫Ω khung bo g√≥c b·∫±ng line + ellipse.
    """
    x1, y1 = top_left
    x2, y2 = bottom_right

    radius = int(min(radius, (x2 - x1) / 2, (y2 - y1) / 2))

    cv2.line(img, (x1 + radius, y1), (x2 - radius, y1), color, thickness)
    cv2.line(img, (x1 + radius, y2), (x2 - radius, y2), color, thickness)
    cv2.line(img, (x1, y1 + radius), (x1, y2 - radius), color, thickness)
    cv2.line(img, (x2, y1 + radius), (x2, y2 - radius), color, thickness)

    cv2.ellipse(img, (x1 + radius, y1 + radius), (radius, radius), 180, 0, 90, color, thickness)
    cv2.ellipse(img, (x2 - radius, y1 + radius), (radius, radius), 270, 0, 90, color, thickness)
    cv2.ellipse(img, (x1 + radius, y2 - radius), (radius, radius), 90, 0, 90, color, thickness)
    cv2.ellipse(img, (x2 - radius, y2 - radius), (radius, radius), 0, 0, 90, color, thickness)


def predict_name_from_gray_face(gray_face):
    """
    D·ª± ƒëo√°n t√™n t·ª´ 1 ·∫£nh m·∫∑t (grayscale 2D) b·∫±ng model KNN t·ª± code.
    """
    if knn_model is None:
        return "Unknown (ch∆∞a c√≥ model)"

    face_resized = cv2.resize(gray_face, IMG_SIZE)
    feat = face_resized.reshape(-1)  # 10000 chi·ªÅu

    try:
        pred = knn_model.predict(feat)[0]
        return str(pred)
    except Exception:
        return "Unknown"


# =========================
# PAGE 1: CH·ª§P ·∫¢NH
# =========================
def page_chup_anh():
    st.markdown('<div class="main-title">H·ªÜ TH·ªêNG NH·∫¨N DI·ªÜN KHU√îN M·∫∂T</div>', unsafe_allow_html=True)
    st.markdown(
        '<div class="sub-title">B∆∞·ªõc 1: Thu th·∫≠p d·ªØ li·ªáu khu√¥n m·∫∑t (crop + grayscale, l∆∞u v√†o dataset)</div>',
        unsafe_allow_html=True,
    )

    st.markdown('<div class="step-box">', unsafe_allow_html=True)
    st.subheader("üì∏ Ch·ª•p ·∫£nh thu th·∫≠p d·ªØ li·ªáu")

    person_name = st.text_input(
        "Nh·∫≠p t√™n / m√£ ƒë·ªãnh danh (n√™n kh√¥ng d·∫•u, kh√¥ng kho·∫£ng tr·∫Øng, v√≠ d·ª•: Manh, Khang, Nguyen_Manh):",
        "",
    )

    if person_name.strip():
        person_folder_path = os.path.join(DATASET_PATH, person_name.strip())
        current_count = 0
        if os.path.exists(person_folder_path):
            current_count = len(
                [
                    f
                    for f in os.listdir(person_folder_path)
                    if os.path.isfile(os.path.join(person_folder_path, f))
                ]
            )
        st.info(f"Hi·ªán c√≥ {current_count} ·∫£nh c·ªßa `{person_name}` trong dataset.")
        st.progress(min(current_count / TARGET_IMAGES_PER_PERSON, 1.0))
    else:
        st.warning("H√£y nh·∫≠p t√™n tr∆∞·ªõc khi ch·ª•p ·∫£nh (∆∞u ti√™n kh√¥ng d·∫•u ƒë·ªÉ tr√°nh l·ªói Unicode).")

    picture = st.camera_input("Ch·ª•p ·∫£nh khu√¥n m·∫∑t", key="camera_capture")

    if picture is not None:
        if not person_name.strip():
            st.error("B·∫°n ch∆∞a nh·∫≠p t√™n/m√£ ƒë·ªãnh danh.")
            return

        bytes_data = picture.getvalue()
        cv2_img = cv2.imdecode(np.frombuffer(bytes_data, np.uint8), cv2.IMREAD_COLOR)

        if cv2_img is None or cv2_img.size == 0:
            st.error("Kh√¥ng ƒë·ªçc ƒë∆∞·ª£c ·∫£nh t·ª´ camera.")
            return

        face_gray, face_color, box = detect_and_crop_face_gray(cv2_img)
        if face_gray is None:
            st.error("Kh√¥ng t√¨m th·∫•y khu√¥n m·∫∑t. H√£y ch·ª•p l·∫°i g·∫ßn h∆°n / s√°ng h∆°n.")
            return

        person_folder_path = os.path.join(DATASET_PATH, person_name.strip())
        success, path = _save_image(face_gray, person_folder_path)

        if success:
            new_count = len(
                [
                    f
                    for f in os.listdir(person_folder_path)
                    if os.path.isfile(os.path.join(person_folder_path, f))
                ]
            )
            st.success(f"ƒê√£ l∆∞u ·∫£nh: {os.path.basename(path)}")
            st.info(f"T·ªïng s·ªë ·∫£nh hi·ªán c√≥ c·ªßa {person_name}: {new_count}")

            st.image(
                cv2.cvtColor(face_color, cv2.COLOR_BGR2RGB),
                caption="Khu√¥n m·∫∑t (m√†u)",
                use_container_width=True,
            )
            st.image(
                face_gray,
                caption="Khu√¥n m·∫∑t (grayscale) ƒë√£ l∆∞u",
                use_container_width=True,
            )
        else:
            st.error(f"L·ªói khi l∆∞u ·∫£nh: {path}")

    st.markdown("</div>", unsafe_allow_html=True)
    st.caption("Sau khi ch·ª•p ƒë·ªß ·∫£nh cho t·ª´ng ng∆∞·ªùi, ch·∫°y `python train_model.py` ƒë·ªÉ t·∫°o data.csv + model_knn.npz.")


# =========================
# PAGE 2: NH·∫¨N DI·ªÜN ·∫¢NH UPLOAD
# =========================
def page_nhan_dien():
    st.markdown('<div class="main-title">NH·∫¨N DI·ªÜN KHU√îN M·∫∂T T·ª™ ·∫¢NH</div>', unsafe_allow_html=True)
    st.markdown(
        '<div class="sub-title">Upload ·∫£nh, h·ªá th·ªëng d√≤ m·∫∑t + g√°n t√™n b·∫±ng KNN t·ª± code</div>',
        unsafe_allow_html=True,
    )

    if knn_model is None:
        st.error(
            "Ch∆∞a load ƒë∆∞·ª£c model KNN.\n\n"
            "- H√£y ƒë·∫£m b·∫£o ƒë√£ ch·∫°y `python train_model.py`\n"
            "- File model ph·∫£i n·∫±m ·ªü: `output/model_knn.npz`"
        )
        return

    uploaded_img = st.file_uploader("Ch·ªçn ·∫£nh ƒë·ªÉ nh·∫≠n di·ªán", type=["jpg", "jpeg", "png"])

    if uploaded_img is None:
        return

    bytes_data = uploaded_img.read()
    cv2_img = cv2.imdecode(np.frombuffer(bytes_data, np.uint8), cv2.IMREAD_COLOR)

    if cv2_img is None or cv2_img.size == 0:
        st.error("Kh√¥ng ƒë·ªçc ƒë∆∞·ª£c ·∫£nh. Th·ª≠ l·∫°i ·∫£nh kh√°c.")
        return

    gray = cv2.cvtColor(cv2_img, cv2.COLOR_BGR2GRAY)
    faces = face_cascade.detectMultiScale(gray, 1.1, 5, minSize=(80, 80))

    if len(faces) == 0:
        st.warning("Kh√¥ng ph√°t hi·ªán khu√¥n m·∫∑t n√†o trong ·∫£nh.")
        st.image(cv2.cvtColor(cv2_img, cv2.COLOR_BGR2RGB), use_container_width=True)
        return

    for (x, y, w, h) in faces:
        face_gray = gray[y:y + h, x:x + w]

        name = predict_name_from_gray_face(face_gray)

        draw_rounded_rectangle(
            cv2_img,
            (x, y),
            (x + w, y + h),
            color=(0, 255, 0),
            thickness=2,
            radius=20,
        )
        cv2.putText(
            cv2_img,
            name,
            (x, y - 10),
            cv2.FONT_HERSHEY_SIMPLEX,
            0.7,
            (0, 255, 0),
            2,
            cv2.LINE_AA,
        )

    st.image(
        cv2.cvtColor(cv2_img, cv2.COLOR_BGR2RGB),
        caption="K·∫øt qu·∫£ nh·∫≠n di·ªán",
        use_container_width=True,
    )


# =========================
# MAIN
# =========================
def main():
    st.sidebar.title("Menu")
    choice = st.sidebar.radio("Ch·ªçn ch·ª©c nƒÉng", ["Ch·ª•p ·∫£nh", "Nh·∫≠n di·ªán"])

    if choice == "Ch·ª•p ·∫£nh":
        page_chup_anh()
    else:
        page_nhan_dien()


if __name__ == "__main__":
    main()
